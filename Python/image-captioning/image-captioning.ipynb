{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9195901-24d3-4dc9-ad62-9cff2ccec9f8",
   "metadata": {},
   "source": [
    "Step 1: Setting up the image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd839da-cc24-40a8-8d70-e8d79cdecd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mshimizu/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75af7ea-26ed-4b02-a3cb-a47836e2c15a",
   "metadata": {},
   "source": [
    "Step 2: Defining a predict function\n",
    "\n",
    "Next, we will need to define a function that takes in the user input, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aeed961-639f-4e7d-9bb3-36e5c469f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "def predict(inp):\n",
    " inp = transforms.ToTensor()(inp).unsqueeze(0)  #inp: the input image as a PIL image\n",
    "    \n",
    " with torch.no_grad():\n",
    "  prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "\n",
    " return confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5591f9-2e56-49fe-a4cd-2fb80f0911b1",
   "metadata": {},
   "source": [
    "Step 3: Creating a Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569ca30d-e784-4d75-b85d-e6388298702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshimizu/.cache/torch/hub/pytorch_vision_v0.6.0/torchvision/transforms/functional.py:74: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict,\n",
    "       inputs=gr.Image(type=\"pil\"),\n",
    "       outputs=gr.Label(num_top_classes=3),\n",
    "       examples=[\"lion.jpg\", \"monkey.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19797803-acea-46e2-aeeb-48a8183e9faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
